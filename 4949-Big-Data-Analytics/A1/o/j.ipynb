{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "\n",
    "from pandas_datareader import data as pdr\n",
    "\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Show all columns.\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "DATAPATH = './jena_climate_2009_2016.csv'\n",
    "\n",
    "data = pd.read_csv(DATAPATH, sep=',')\n",
    "\n",
    "\n",
    "# Make dates actual dates\n",
    "data['Date Time'] = pd.to_datetime(data['Date Time'])\n",
    "\n",
    "for col in data.iloc[:,2:].columns:\n",
    "    if data[col].dtypes == object:\n",
    "        data[col] = data[col].str.replace(',', '.').astype('float')\n",
    "\n",
    "data.head()\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "# Compute the average considering only the positive values\n",
    "def positive_average(num):\n",
    "    return num[num > -200].mean()\n",
    "\n",
    "# # Aggregate data\n",
    "# daily_data = data.drop('Time', axis=1).groupby('Date').apply(positive_average)\n",
    "\n",
    "# # Drop columns with more than 8 NaN\n",
    "# daily_data = daily_data.iloc[:,(daily_data.isna().sum() <= 8).values]\n",
    "\n",
    "# # Remove rows containing NaN values\n",
    "# daily_data = daily_data.dropna()\n",
    "\n",
    "# # Aggregate data by week\n",
    "# weekly_data = daily_data.resample('W').mean()\n",
    "\n",
    "# Plot the weekly concentration of each gas\n",
    "def plot_data():\n",
    "    weekly_data=data.resample('W', on='Date Time').mean()\n",
    "    plt.figure(figsize=(17, 8))\n",
    "    plt.plot(weekly_data['T (degC)'])\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel(col)\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "plot_data()\n",
    "\n",
    "def plot_data():\n",
    "    weekly_data=data.resample('M', on='Date Time').mean()\n",
    "    plt.figure(figsize=(17, 8))\n",
    "    plt.plot(weekly_data['T (degC)'])\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel(col)\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "plot_data()\n",
    "\n",
    "\n",
    "# In[147]:\n",
    "\n",
    "\n",
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yfin # Work around until\n",
    "                        # pandas_datareader is fixed.\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Do not show warning.\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "dfPredictions = pd.DataFrame()\n",
    "##################################################################\n",
    "# CONFIGURATION SECTION\n",
    "NUM_DAYS        = 1200\n",
    "NUM_TIME_STEPS  = 2\n",
    "TEST_DAYS       = 10\n",
    "##################################################################\n",
    "\n",
    "daily_data = data.resample('D', on='Date Time').mean()\n",
    "# Creates time shifted columns for as many time steps needed.\n",
    "def backShiftColumns(df, originalColName, numTimeSteps):\n",
    "    dfNew  = df[[originalColName]]\n",
    "\n",
    "    for i in range(1, numTimeSteps + 1):\n",
    "        newColName       = originalColName + 't-' + str(i)\n",
    "        dfNew[newColName]= dfNew[originalColName].shift(periods=i)\n",
    "    return dfNew\n",
    "\n",
    "def prepareStockDf(columns):\n",
    "    df = daily_data\n",
    "    print(df.head())\n",
    "    # Create data frame with back shift columns for all features of interest.\n",
    "    mergedDf = pd.DataFrame()\n",
    "    for i in range(0, len(columns)):\n",
    "        backShiftedDf  = backShiftColumns(df, columns[i], NUM_TIME_STEPS)\n",
    "        if(i==0):\n",
    "            mergedDf = backShiftedDf\n",
    "        else:\n",
    "            mergedDf = mergedDf.merge(backShiftedDf, left_index=True,\n",
    "                       right_index=True)\n",
    "\n",
    "    newColumns = list(mergedDf.keys())\n",
    "\n",
    "    # Append stock symbol to column names.\n",
    "    for i in range(0, len(newColumns)):\n",
    "        mergedDf.rename(columns={newColumns[i]: \"BackShift\" +                        \"_\" + newColumns[i]}, inplace=True)\n",
    "\n",
    "    return mergedDf\n",
    "\n",
    "columns  = list(daily_data.columns.values)[0::]\n",
    "# columns = ['T (degC)']\n",
    "mergedDf1   = prepareStockDf(columns)\n",
    "# aaplDf   = data['T (degC)']\n",
    "mergedDf = daily_data.merge(mergedDf1, left_index=True, right_index=True)\n",
    "mergedDf = mergedDf.dropna()\n",
    "print(mergedDf)\n",
    "\n",
    "# import seaborn as sns\n",
    "\n",
    "# corr = mergedDf.corr()\n",
    "# plt.figure(figsize = (4,4))\n",
    "# ax = sns.heatmap(corr[['MSFT_Open']],\n",
    "#             linewidth=0.5, vmin=-1,\n",
    "#             vmax=1, cmap=\"YlGnBu\")\n",
    "# plt.show()\n",
    "\n",
    "# xfeatures = ['MSFT_Ct-2', 'GOOGL_Ct-1']\n",
    "\n",
    "xfeatures = list(mergedDf.columns.values)[::]\n",
    "print(xfeatures)\n",
    "xfeatures.remove('T (degC)')\n",
    "xfeatures.remove('BackShift_T (degC)')\n",
    "xfeatures.remove('p (mbar)')\n",
    "xfeatures.remove('BackShift_p (mbar)')\n",
    "xfeatures.remove('Tpot (K)')\n",
    "xfeatures.remove('BackShift_Tpot (K)')\n",
    "xfeatures.remove('Tdew (degC)')\n",
    "xfeatures.remove('BackShift_Tdew (degC)')\n",
    "xfeatures.remove('rh (%)')\n",
    "xfeatures.remove('BackShift_rh (%)')\n",
    "xfeatures.remove('VPmax (mbar)')\n",
    "xfeatures.remove('BackShift_VPmax (mbar)')\n",
    "xfeatures.remove('VPdef (mbar)')\n",
    "xfeatures.remove('BackShift_VPdef (mbar)')\n",
    "xfeatures.remove('sh (g/kg)')\n",
    "xfeatures.remove('BackShift_sh (g/kg)')\n",
    "xfeatures.remove('H2OC (mmol/mol)')\n",
    "xfeatures.remove('BackShift_H2OC (mmol/mol)')\n",
    "xfeatures.remove('rho (g/m**3)')\n",
    "xfeatures.remove('BackShift_rho (g/m**3)')\n",
    "xfeatures.remove('wv (m/s)')\n",
    "xfeatures.remove('BackShift_wv (m/s)')\n",
    "xfeatures.remove('max. wv (m/s)')\n",
    "xfeatures.remove('BackShift_max. wv (m/s)')\n",
    "xfeatures.remove('wd (deg)')\n",
    "xfeatures.remove('BackShift_wd (deg)')\n",
    "xfeatures.remove('VPact (mbar)')\n",
    "# xfeatures.remove('max. wv (m/s)')\n",
    "xfeatures.remove('BackShift_p (mbar)t-2')\n",
    "# xfeatures.remove('BackShift_T (degC)t-2')\n",
    "xfeatures.remove('BackShift_Tdew (degC)t-2')\n",
    "xfeatures.remove('BackShift_rh (%)t-1')\n",
    "xfeatures.remove('BackShift_rh (%)t-2')\n",
    "xfeatures.remove('BackShift_VPmax (mbar)t-1')\n",
    "xfeatures.remove('BackShift_VPmax (mbar)t-2')\n",
    "xfeatures.remove('BackShift_VPact (mbar)t-2')\n",
    "xfeatures.remove('BackShift_VPdef (mbar)t-1')\n",
    "xfeatures.remove('BackShift_VPdef (mbar)t-2')\n",
    "xfeatures.remove('BackShift_sh (g/kg)t-1')\n",
    "xfeatures.remove('BackShift_sh (g/kg)t-2')\n",
    "xfeatures.remove('BackShift_H2OC (mmol/mol)t-1')\n",
    "xfeatures.remove('BackShift_H2OC (mmol/mol)t-2')\n",
    "xfeatures.remove('BackShift_rho (g/m**3)t-2')\n",
    "xfeatures.remove('BackShift_wv (m/s)t-1')\n",
    "xfeatures.remove('BackShift_max. wv (m/s)t-1')\n",
    "xfeatures.remove('BackShift_max. wv (m/s)t-2')\n",
    "xfeatures.remove('BackShift_wd (deg)t-1')\n",
    "xfeatures.remove('BackShift_T (degC)t-2')\n",
    "xfeatures.remove('BackShift_Tpot (K)t-2')\n",
    "xfeatures.remove('BackShift_wv (m/s)t-2')\n",
    "print(xfeatures)\n",
    "X = mergedDf[xfeatures]\n",
    "y = mergedDf[['T (degC)']]\n",
    "\n",
    "# Add intercept for OLS regression.\n",
    "import statsmodels.api       as sm\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Split into test and train sets. The test data must be\n",
    "# the latest data range.\n",
    "lenData = len(X)\n",
    "X_train = X[0:lenData-TEST_DAYS]\n",
    "y_train = y[0:lenData-TEST_DAYS]\n",
    "X_test  = X[lenData-TEST_DAYS:]\n",
    "y_test  = y[lenData-TEST_DAYS:]\n",
    "\n",
    "# Model and make predictions.\n",
    "modelOLS       = sm.OLS(y_train, X_train).fit()\n",
    "print(modelOLS.summary())\n",
    "predictions = modelOLS.predict(X_test)\n",
    "dfPredictions['OLS'] = predictions\n",
    "print('********')\n",
    "print(dfPredictions)\n",
    "# Show RMSE and plot the data.\n",
    "from sklearn  import metrics\n",
    "import numpy as np\n",
    "print('Root Mean Squared Error:',\n",
    "      np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "\n",
    "plt.figure(figsize=(17, 8))\n",
    "plt.plot(y_test, label='Actual')\n",
    "plt.plot(predictions, label='Predicted')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[148]:\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yfin  # Work around until\n",
    "                         # pandas_datareader is fixed.\n",
    "import datetime\n",
    "import pmdarima as pm\n",
    "\n",
    "\n",
    "TOTAL_DAYS = 10\n",
    "\n",
    "arimaDf = daily_data.copy()\n",
    "\n",
    "# Build feature set with backshifted closing prices.\n",
    "arimaDf['Tdew (degC)_t-1'] = arimaDf['Tdew (degC)'].shift(1)\n",
    "arimaDf              = arimaDf.dropna()\n",
    "dfX                  = arimaDf[['T (degC)', 'Tdew (degC)_t-1']]\n",
    "size                 = len(dfX) - TOTAL_DAYS\n",
    "train, test          = dfX[0:size], dfX[size:]\n",
    "\n",
    "# Create training set and copy of the training set.\n",
    "train.tail(TOTAL_DAYS)\n",
    "history     = train.copy()\n",
    "predictions = []\n",
    "\n",
    "# Iterate to make predictions for the evaluation set.\n",
    "for i in range(0, len(test)):\n",
    "    lenOpen = len(history[['Tdew (degC)_t-1']])\n",
    "    print(\"\\n\\nModel \" + str(i))\n",
    "#     print(history.shape)\n",
    "\n",
    "    model = pm.auto_arima(history[['T (degC)']],\n",
    "                          exogenous=history[['Tdew (degC)_t-1']],\n",
    "                          start_p=1, start_q=1,\n",
    "                          test='adf',       # Use adftest to find optimal 'd'\n",
    "                          max_p=3, max_q=3, # Set maximum p and q.\n",
    "                          d=None,           # Let model determine 'd'.\n",
    "                          trace=True,\n",
    "                          error_action='ignore',\n",
    "                          suppress_warnings=True)\n",
    "    fc, confint = model.predict(n_periods=1,\n",
    "                          exogenous=np.array(\n",
    "                          history.iloc[lenOpen-1]['Tdew (degC)_t-1']).reshape(1,-1),\n",
    "                          return_conf_int=True)\n",
    "    predictions.append(fc)\n",
    "    open        = test.iloc[i]['T (degC)']\n",
    "    close_t_1   = test.iloc[i]['Tdew (degC)_t-1']\n",
    "    history     = history.append({\"T (degC)\":open, \"Tdew (degC)_t-1\":close_t_1},\n",
    "                                 ignore_index=True)\n",
    "\n",
    "\n",
    "# dfPredictions['ARIMA'] = predictions\n",
    "plt.plot(test.index, test['T (degC)'], marker='o',\n",
    "         label='Actual', color='blue')\n",
    "plt.plot(test.index, predictions, marker='o',\n",
    "         label='Predicted', color='orange')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=70)\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "rmse = sqrt(mean_squared_error(test['T (degC)'], predictions))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "\n",
    "\n",
    "# In[151]:\n",
    "\n",
    "\n",
    "# print(model)\n",
    "# arimaModel = model\n",
    "# print(arimaModel)\n",
    "tempList = []\n",
    "for each in predictions:\n",
    "    tempList.append(each.values)\n",
    "\n",
    "dfPredictions['ARIMA'] = np.array(tempList)\n",
    "print(dfPredictions)\n",
    "\n",
    "\n",
    "# In[153]:\n",
    "\n",
    "\n",
    "# Pandas is used for data manipulation\n",
    "import pandas as pd\n",
    "from   sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Read in data and display first 5 rows\n",
    "features = daily_data.copy()\n",
    "features.dropna()\n",
    "features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Show all columns.\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "print(features.describe())\n",
    "\n",
    "# Use numpy to convert to arrays\n",
    "import numpy as np\n",
    "\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(features['T (degC)'])\n",
    "print(np.isnan(features))\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= features.drop('T (degC)', axis = 1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(features)\n",
    "\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels =    train_test_split(features, labels, test_size = 0.25, random_state = 42)\n",
    "\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "\n",
    "print('test')\n",
    "# print(np.isnan(train_features).any())\n",
    "# print(np.isnan(train_labels).any())\n",
    "\n",
    "\n",
    "# print(test_labels)\n",
    "train_features = X_train\n",
    "train_labels = y_train\n",
    "test_features = X_test\n",
    "test_labels = y_test['T (degC)']\n",
    "\n",
    "# train_features = np.nan_to_num(train_features)\n",
    "# train_labels = np.nan_to_num(train_labels)\n",
    "# test_features = np.nan_to_num(test_features)\n",
    "# test_labels = np.nan_to_num(test_labels)\n",
    "\n",
    "print('test')\n",
    "# print(test_labels)\n",
    "# print(np.isnan(train_features).any())\n",
    "# print(np.isnan(train_labels).any())\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels)\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "print('test')\n",
    "print(predictions)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / test_labels)\n",
    "\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "\n",
    "print('Accuracy:', round(accuracy, 2), '%.')\n",
    "\n",
    "# Print out the mean square error.\n",
    "mse = mean_squared_error(test_labels, predictions)\n",
    "print('RMSE:', np.sqrt(mse))\n",
    "\n",
    "print('dfPred')\n",
    "print(dfPredictions)\n",
    "dfPredictions['RF'] = predictions\n",
    "\n",
    "\n",
    "# In[155]:\n",
    "\n",
    "\n",
    "print(dfPredictions)\n",
    "print(test_labels)\n",
    "\n",
    "\n",
    "# In[164]:\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "stackedModel = LinearRegression()\n",
    "stackedModel.fit(dfPredictions, test_labels)\n",
    "\n",
    "stackedPredictions = stackedModel.predict(dfPredictions)\n",
    "\n",
    "def evaluateModel(y_test, predictions, model):\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = round(np.sqrt(mse),3)\n",
    "    print(\" RMSE:\" + str(rmse) + \" \" + model.__class__.__name__)\n",
    "\n",
    "print(\"\\n** Evaluate Stacked Model **\")\n",
    "evaluateModel(test_labels, stackedPredictions, stackedModel)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
