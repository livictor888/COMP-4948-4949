{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>pre { white-space: pre !important; }</style>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './jena_climate_2009_2016.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 35>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     31\u001B[0m pd\u001B[38;5;241m.\u001B[39mset_option(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdisplay.width\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m1000\u001B[39m)\n\u001B[0;32m     33\u001B[0m DATAPATH \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./jena_climate_2009_2016.csv\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m---> 35\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mDATAPATH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m,\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# Make dates actual dates\u001B[39;00m\n\u001B[0;32m     39\u001B[0m data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDate Time\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_datetime(data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDate Time\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\COMP3948_Predictive_Modelling\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    210\u001B[0m         kwargs[new_arg_name] \u001B[38;5;241m=\u001B[39m new_arg_value\n\u001B[1;32m--> 211\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\COMP3948_Predictive_Modelling\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[0;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[0;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[0;32m    330\u001B[0m     )\n\u001B[1;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\COMP3948_Predictive_Modelling\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    936\u001B[0m     dialect,\n\u001B[0;32m    937\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    946\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[0;32m    947\u001B[0m )\n\u001B[0;32m    948\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 950\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\COMP3948_Predictive_Modelling\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    602\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    604\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 605\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    607\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    608\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\COMP3948_Predictive_Modelling\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1439\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1441\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1442\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\COMP3948_Predictive_Modelling\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1733\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1734\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1735\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1736\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1737\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1738\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1739\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1740\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1741\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1742\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1743\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1744\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1745\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1746\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\COMP3948_Predictive_Modelling\\lib\\site-packages\\pandas\\io\\common.py:856\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    851\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    852\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    853\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    854\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    855\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 856\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    857\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    858\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    859\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    860\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    861\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    862\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    863\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    864\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    865\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: './jena_climate_2009_2016.csv'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "\n",
    "from pandas_datareader import data as pdr\n",
    "\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Show all columns.\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "DATAPATH = './jena_climate_2009_2016.csv'\n",
    "\n",
    "data = pd.read_csv(DATAPATH, sep=',')\n",
    "\n",
    "\n",
    "# Make dates actual dates\n",
    "data['Date Time'] = pd.to_datetime(data['Date Time'])\n",
    "\n",
    "for col in data.iloc[:,2:].columns:\n",
    "    if data[col].dtypes == object:\n",
    "        data[col] = data[col].str.replace(',', '.').astype('float')\n",
    "\n",
    "data.head()\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "# Compute the average considering only the positive values\n",
    "def positive_average(num):\n",
    "    return num[num > -200].mean()\n",
    "\n",
    "# # Aggregate data\n",
    "# daily_data = data.drop('Time', axis=1).groupby('Date').apply(positive_average)\n",
    "\n",
    "# # Drop columns with more than 8 NaN\n",
    "# daily_data = daily_data.iloc[:,(daily_data.isna().sum() <= 8).values]\n",
    "\n",
    "# # Remove rows containing NaN values\n",
    "# daily_data = daily_data.dropna()\n",
    "\n",
    "# # Aggregate data by week\n",
    "# weekly_data = daily_data.resample('W').mean()\n",
    "\n",
    "# Plot the weekly concentration of each gas\n",
    "def plot_data():\n",
    "    weekly_data=data.resample('W', on='Date Time').mean()\n",
    "    plt.figure(figsize=(17, 8))\n",
    "    plt.plot(weekly_data['T (degC)'])\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel(col)\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "plot_data()\n",
    "\n",
    "def plot_data():\n",
    "    weekly_data=data.resample('M', on='Date Time').mean()\n",
    "    plt.figure(figsize=(17, 8))\n",
    "    plt.plot(weekly_data['T (degC)'])\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel(col)\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "plot_data()\n",
    "\n",
    "\n",
    "# In[147]:\n",
    "\n",
    "\n",
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yfin # Work around until\n",
    "                        # pandas_datareader is fixed.\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Do not show warning.\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "dfPredictions = pd.DataFrame()\n",
    "##################################################################\n",
    "# CONFIGURATION SECTION\n",
    "NUM_DAYS        = 1200\n",
    "NUM_TIME_STEPS  = 2\n",
    "TEST_DAYS       = 10\n",
    "##################################################################\n",
    "\n",
    "daily_data = data.resample('D', on='Date Time').mean()\n",
    "# Creates time shifted columns for as many time steps needed.\n",
    "def backShiftColumns(df, originalColName, numTimeSteps):\n",
    "    dfNew  = df[[originalColName]]\n",
    "\n",
    "    for i in range(1, numTimeSteps + 1):\n",
    "        newColName       = originalColName + 't-' + str(i)\n",
    "        dfNew[newColName]= dfNew[originalColName].shift(periods=i)\n",
    "    return dfNew\n",
    "\n",
    "def prepareStockDf(columns):\n",
    "    df = daily_data\n",
    "    print(df.head())\n",
    "    # Create data frame with back shift columns for all features of interest.\n",
    "    mergedDf = pd.DataFrame()\n",
    "    for i in range(0, len(columns)):\n",
    "        backShiftedDf  = backShiftColumns(df, columns[i], NUM_TIME_STEPS)\n",
    "        if(i==0):\n",
    "            mergedDf = backShiftedDf\n",
    "        else:\n",
    "            mergedDf = mergedDf.merge(backShiftedDf, left_index=True,\n",
    "                       right_index=True)\n",
    "\n",
    "    newColumns = list(mergedDf.keys())\n",
    "\n",
    "    # Append stock symbol to column names.\n",
    "    for i in range(0, len(newColumns)):\n",
    "        mergedDf.rename(columns={newColumns[i]: \"BackShift\" +                        \"_\" + newColumns[i]}, inplace=True)\n",
    "\n",
    "    return mergedDf\n",
    "\n",
    "columns  = list(daily_data.columns.values)[0::]\n",
    "# columns = ['T (degC)']\n",
    "mergedDf1   = prepareStockDf(columns)\n",
    "# aaplDf   = data['T (degC)']\n",
    "mergedDf = daily_data.merge(mergedDf1, left_index=True, right_index=True)\n",
    "mergedDf = mergedDf.dropna()\n",
    "print(mergedDf)\n",
    "\n",
    "# import seaborn as sns\n",
    "\n",
    "# corr = mergedDf.corr()\n",
    "# plt.figure(figsize = (4,4))\n",
    "# ax = sns.heatmap(corr[['MSFT_Open']],\n",
    "#             linewidth=0.5, vmin=-1,\n",
    "#             vmax=1, cmap=\"YlGnBu\")\n",
    "# plt.show()\n",
    "\n",
    "# xfeatures = ['MSFT_Ct-2', 'GOOGL_Ct-1']\n",
    "\n",
    "xfeatures = list(mergedDf.columns.values)[::]\n",
    "print(xfeatures)\n",
    "xfeatures.remove('T (degC)')\n",
    "xfeatures.remove('BackShift_T (degC)')\n",
    "xfeatures.remove('p (mbar)')\n",
    "xfeatures.remove('BackShift_p (mbar)')\n",
    "xfeatures.remove('Tpot (K)')\n",
    "xfeatures.remove('BackShift_Tpot (K)')\n",
    "xfeatures.remove('Tdew (degC)')\n",
    "xfeatures.remove('BackShift_Tdew (degC)')\n",
    "xfeatures.remove('rh (%)')\n",
    "xfeatures.remove('BackShift_rh (%)')\n",
    "xfeatures.remove('VPmax (mbar)')\n",
    "xfeatures.remove('BackShift_VPmax (mbar)')\n",
    "xfeatures.remove('VPdef (mbar)')\n",
    "xfeatures.remove('BackShift_VPdef (mbar)')\n",
    "xfeatures.remove('sh (g/kg)')\n",
    "xfeatures.remove('BackShift_sh (g/kg)')\n",
    "xfeatures.remove('H2OC (mmol/mol)')\n",
    "xfeatures.remove('BackShift_H2OC (mmol/mol)')\n",
    "xfeatures.remove('rho (g/m**3)')\n",
    "xfeatures.remove('BackShift_rho (g/m**3)')\n",
    "xfeatures.remove('wv (m/s)')\n",
    "xfeatures.remove('BackShift_wv (m/s)')\n",
    "xfeatures.remove('max. wv (m/s)')\n",
    "xfeatures.remove('BackShift_max. wv (m/s)')\n",
    "xfeatures.remove('wd (deg)')\n",
    "xfeatures.remove('BackShift_wd (deg)')\n",
    "xfeatures.remove('VPact (mbar)')\n",
    "# xfeatures.remove('max. wv (m/s)')\n",
    "xfeatures.remove('BackShift_p (mbar)t-2')\n",
    "# xfeatures.remove('BackShift_T (degC)t-2')\n",
    "xfeatures.remove('BackShift_Tdew (degC)t-2')\n",
    "xfeatures.remove('BackShift_rh (%)t-1')\n",
    "xfeatures.remove('BackShift_rh (%)t-2')\n",
    "xfeatures.remove('BackShift_VPmax (mbar)t-1')\n",
    "xfeatures.remove('BackShift_VPmax (mbar)t-2')\n",
    "xfeatures.remove('BackShift_VPact (mbar)t-2')\n",
    "xfeatures.remove('BackShift_VPdef (mbar)t-1')\n",
    "xfeatures.remove('BackShift_VPdef (mbar)t-2')\n",
    "xfeatures.remove('BackShift_sh (g/kg)t-1')\n",
    "xfeatures.remove('BackShift_sh (g/kg)t-2')\n",
    "xfeatures.remove('BackShift_H2OC (mmol/mol)t-1')\n",
    "xfeatures.remove('BackShift_H2OC (mmol/mol)t-2')\n",
    "xfeatures.remove('BackShift_rho (g/m**3)t-2')\n",
    "xfeatures.remove('BackShift_wv (m/s)t-1')\n",
    "xfeatures.remove('BackShift_max. wv (m/s)t-1')\n",
    "xfeatures.remove('BackShift_max. wv (m/s)t-2')\n",
    "xfeatures.remove('BackShift_wd (deg)t-1')\n",
    "xfeatures.remove('BackShift_T (degC)t-2')\n",
    "xfeatures.remove('BackShift_Tpot (K)t-2')\n",
    "xfeatures.remove('BackShift_wv (m/s)t-2')\n",
    "print(xfeatures)\n",
    "X = mergedDf[xfeatures]\n",
    "y = mergedDf[['T (degC)']]\n",
    "\n",
    "# Add intercept for OLS regression.\n",
    "import statsmodels.api       as sm\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Split into test and train sets. The test data must be\n",
    "# the latest data range.\n",
    "lenData = len(X)\n",
    "X_train = X[0:lenData-TEST_DAYS]\n",
    "y_train = y[0:lenData-TEST_DAYS]\n",
    "X_test  = X[lenData-TEST_DAYS:]\n",
    "y_test  = y[lenData-TEST_DAYS:]\n",
    "\n",
    "# Model and make predictions.\n",
    "modelOLS       = sm.OLS(y_train, X_train).fit()\n",
    "print(modelOLS.summary())\n",
    "predictions = modelOLS.predict(X_test)\n",
    "dfPredictions['OLS'] = predictions\n",
    "print('********')\n",
    "print(dfPredictions)\n",
    "# Show RMSE and plot the data.\n",
    "from sklearn  import metrics\n",
    "import numpy as np\n",
    "print('Root Mean Squared Error:',\n",
    "      np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "\n",
    "plt.figure(figsize=(17, 8))\n",
    "plt.plot(y_test, label='Actual')\n",
    "plt.plot(predictions, label='Predicted')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[148]:\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yfin  # Work around until\n",
    "                         # pandas_datareader is fixed.\n",
    "import datetime\n",
    "import pmdarima as pm\n",
    "\n",
    "\n",
    "TOTAL_DAYS = 10\n",
    "\n",
    "arimaDf = daily_data.copy()\n",
    "\n",
    "# Build feature set with backshifted closing prices.\n",
    "arimaDf['Tdew (degC)_t-1'] = arimaDf['Tdew (degC)'].shift(1)\n",
    "arimaDf              = arimaDf.dropna()\n",
    "dfX                  = arimaDf[['T (degC)', 'Tdew (degC)_t-1']]\n",
    "size                 = len(dfX) - TOTAL_DAYS\n",
    "train, test          = dfX[0:size], dfX[size:]\n",
    "\n",
    "# Create training set and copy of the training set.\n",
    "train.tail(TOTAL_DAYS)\n",
    "history     = train.copy()\n",
    "predictions = []\n",
    "\n",
    "# Iterate to make predictions for the evaluation set.\n",
    "for i in range(0, len(test)):\n",
    "    lenOpen = len(history[['Tdew (degC)_t-1']])\n",
    "    print(\"\\n\\nModel \" + str(i))\n",
    "#     print(history.shape)\n",
    "\n",
    "    model = pm.auto_arima(history[['T (degC)']],\n",
    "                          exogenous=history[['Tdew (degC)_t-1']],\n",
    "                          start_p=1, start_q=1,\n",
    "                          test='adf',       # Use adftest to find optimal 'd'\n",
    "                          max_p=3, max_q=3, # Set maximum p and q.\n",
    "                          d=None,           # Let model determine 'd'.\n",
    "                          trace=True,\n",
    "                          error_action='ignore',\n",
    "                          suppress_warnings=True)\n",
    "    fc, confint = model.predict(n_periods=1,\n",
    "                          exogenous=np.array(\n",
    "                          history.iloc[lenOpen-1]['Tdew (degC)_t-1']).reshape(1,-1),\n",
    "                          return_conf_int=True)\n",
    "    predictions.append(fc)\n",
    "    open        = test.iloc[i]['T (degC)']\n",
    "    close_t_1   = test.iloc[i]['Tdew (degC)_t-1']\n",
    "    history     = history.append({\"T (degC)\":open, \"Tdew (degC)_t-1\":close_t_1},\n",
    "                                 ignore_index=True)\n",
    "\n",
    "\n",
    "# dfPredictions['ARIMA'] = predictions\n",
    "plt.plot(test.index, test['T (degC)'], marker='o',\n",
    "         label='Actual', color='blue')\n",
    "plt.plot(test.index, predictions, marker='o',\n",
    "         label='Predicted', color='orange')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=70)\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "rmse = sqrt(mean_squared_error(test['T (degC)'], predictions))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "\n",
    "\n",
    "# In[151]:\n",
    "\n",
    "\n",
    "# print(model)\n",
    "# arimaModel = model\n",
    "# print(arimaModel)\n",
    "tempList = []\n",
    "for each in predictions:\n",
    "    tempList.append(each.values)\n",
    "\n",
    "dfPredictions['ARIMA'] = np.array(tempList)\n",
    "print(dfPredictions)\n",
    "\n",
    "\n",
    "# In[153]:\n",
    "\n",
    "\n",
    "# Pandas is used for data manipulation\n",
    "import pandas as pd\n",
    "from   sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Read in data and display first 5 rows\n",
    "features = daily_data.copy()\n",
    "features.dropna()\n",
    "features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Show all columns.\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "print(features.describe())\n",
    "\n",
    "# Use numpy to convert to arrays\n",
    "import numpy as np\n",
    "\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(features['T (degC)'])\n",
    "print(np.isnan(features))\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= features.drop('T (degC)', axis = 1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(features)\n",
    "\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels =    train_test_split(features, labels, test_size = 0.25, random_state = 42)\n",
    "\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "\n",
    "print('test')\n",
    "# print(np.isnan(train_features).any())\n",
    "# print(np.isnan(train_labels).any())\n",
    "\n",
    "\n",
    "# print(test_labels)\n",
    "train_features = X_train\n",
    "train_labels = y_train\n",
    "test_features = X_test\n",
    "test_labels = y_test['T (degC)']\n",
    "\n",
    "# train_features = np.nan_to_num(train_features)\n",
    "# train_labels = np.nan_to_num(train_labels)\n",
    "# test_features = np.nan_to_num(test_features)\n",
    "# test_labels = np.nan_to_num(test_labels)\n",
    "\n",
    "print('test')\n",
    "# print(test_labels)\n",
    "# print(np.isnan(train_features).any())\n",
    "# print(np.isnan(train_labels).any())\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels)\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "print('test')\n",
    "print(predictions)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / test_labels)\n",
    "\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "\n",
    "print('Accuracy:', round(accuracy, 2), '%.')\n",
    "\n",
    "# Print out the mean square error.\n",
    "mse = mean_squared_error(test_labels, predictions)\n",
    "print('RMSE:', np.sqrt(mse))\n",
    "\n",
    "print('dfPred')\n",
    "print(dfPredictions)\n",
    "dfPredictions['RF'] = predictions\n",
    "\n",
    "\n",
    "# In[155]:\n",
    "\n",
    "\n",
    "print(dfPredictions)\n",
    "print(test_labels)\n",
    "\n",
    "\n",
    "# In[164]:\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "stackedModel = LinearRegression()\n",
    "stackedModel.fit(dfPredictions, test_labels)\n",
    "\n",
    "stackedPredictions = stackedModel.predict(dfPredictions)\n",
    "\n",
    "def evaluateModel(y_test, predictions, model):\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = round(np.sqrt(mse),3)\n",
    "    print(\" RMSE:\" + str(rmse) + \" \" + model.__class__.__name__)\n",
    "\n",
    "print(\"\\n** Evaluate Stacked Model **\")\n",
    "evaluateModel(test_labels, stackedPredictions, stackedModel)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
